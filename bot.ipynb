{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader,DirectoryLoader\n",
    "from langchain_astradb import AstraDBVectorStore\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI,GoogleGenerativeAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel,Field\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.utilities import ArxivAPIWrapper,WikipediaAPIWrapper\n",
    "from langchain_community.tools import ArxivQueryRun,WikipediaQueryRun\n",
    "from langchain import hub\n",
    "from langchain.schema import Document\n",
    "from typing import List,Literal\n",
    "from typing_extensions import TypedDict\n",
    "from langchain.schema import Document\n",
    "from pprint import pprint\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "LANGCHAIN_API_KEY = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "LANGCHAIN_PROJECT=\"Langgraph_bot\"\n",
    "LANGCHAIN_TRACING_V2= True \n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a large language model, trained by Google. \n",
      "\n",
      "Here's what that means:\n",
      "\n",
      "* **I am a computer program:** I don't have feelings, experiences, or a physical body.\n",
      "* **I am trained on a massive amount of text data:** This allows me to communicate and generate human-like text in response to a wide range of prompts. \n",
      "* **I can help you with various tasks:** From answering questions to writing stories, translating languages, and summarizing text, I am here to assist you.\n",
      "\n",
      "How can I help you today? \n",
      "\n"
     ]
    }
   ],
   "source": [
    "llm = ChatGoogleGenerativeAI(model = \"gemini-1.5-pro\",api_key = GOOGLE_API_KEY,temperature = 0.2)\n",
    "print(llm.invoke(\"Who are you?\").content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATA-INGESTION & CONVERSION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf(data):\n",
    "    loader = DirectoryLoader(path = data,glob = \"*.pdf\",loader_cls = PyPDFLoader)\n",
    "    docs = loader.load()\n",
    "    return docs\n",
    "\n",
    "extracted_data = load_pdf(\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "\n",
    "\n",
    "    return text_chunks\n",
    "\n",
    "text_chunks = text_split(extracted_data)\n",
    "len(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "gemini_embeddings = GoogleGenerativeAIEmbeddings(model = \"models/embedding-001\")\n",
    "ASTRA_DB_API = os.getenv(\"ASTRA_API_KEY\")\n",
    "ASTRA_ENDPOINT = os.getenv(\"DB_ENDPOINT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest(status):\n",
    "    vector_store = AstraDBVectorStore(token = ASTRA_DB_API,\n",
    "                                      api_endpoint = ASTRA_ENDPOINT,\n",
    "                                      embedding = gemini_embeddings,\n",
    "                                      namespace = \"law\",\n",
    "                                      collection_name = \"langgraph_RAG\")\n",
    "    is_full = status\n",
    "    if is_full == None:#THIS MEANS THERE IS NO VECTORS CREATED IN DB\n",
    "        inserted_ids = vector_store.add_documents(text_chunks)\n",
    "    else:\n",
    "        return vector_store\n",
    "    \n",
    "    \n",
    "    return vector_store,inserted_ids\n",
    "\n",
    "vector_store = ingest(None)#IF YOU ARE RUNNING THIS FOR 2nd TIME CHANGE PARAMETER TO \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = AstraDBVectorStore(token = ASTRA_DB_API,\n",
    "                                      api_endpoint = ASTRA_ENDPOINT,\n",
    "                                      embedding = gemini_embeddings,\n",
    "                                      namespace = \"law\",\n",
    "                                      collection_name = \"langgraph_RAG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ROUTING IN THE GRAPH**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Key 'title' is not supported in schema, ignoring\n",
      "Key 'title' is not supported in schema, ignoring\n",
      "Key 'title' is not supported in schema, ignoring\n",
      "Key 'title' is not supported in schema, ignoring\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'args': {'datasource': 'vectorstore'}, 'type': 'Route_Query'}]\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "\n",
    "class Route_Query(BaseModel):\n",
    "    datasource: Literal[\"vectorstore\", \"wiki_search\"] = Field(..., description=\"For a given user question decide whether to route it to vectorstore or wiki_search\")\n",
    "\n",
    "llm_router = llm.with_structured_output(Route_Query)\n",
    "\n",
    "system = \"\"\"You are an expert at routing a user question to a vectorstore or wiki_search.\n",
    "The vectorstore contains documents related to Indian law budget 2024.\n",
    "Use the vectorstore for questions on these topics. Otherwise, use wiki_search.\"\"\"\n",
    "\n",
    "route_prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", \"{question}\")])\n",
    "\n",
    "question_router = route_prompt | llm_router\n",
    "\n",
    "print(question_router.invoke({\"question\": \"Tell me about Shrimp Production & Export in budget 2024?\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DOCUMENT GRADER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Key 'title' is not supported in schema, ignoring\n",
      "Key 'title' is not supported in schema, ignoring\n",
      "Key 'title' is not supported in schema, ignoring\n",
      "Key 'title' is not supported in schema, ignoring\n",
      "c:\\a\\envs\\main\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'args': {'binary_score': 'yes'}, 'type': 'Grade_Docs'}]\n"
     ]
    }
   ],
   "source": [
    "class Grade_Docs(BaseModel):\n",
    "    binary_score : Literal[\"yes\",\"no\"] = Field(...,description = \"Documents are relevant to the question, 'yes' or 'no'\")\n",
    "\n",
    "system = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n\n",
    "    If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "    It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\"\n",
    "\n",
    "grade_prompt = ChatPromptTemplate.from_messages([(\"system\", system),(\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),])\n",
    "\n",
    "llm_grader = llm.with_structured_output(Grade_Docs)\n",
    "\n",
    "retrieval_grader = grade_prompt | llm_grader\n",
    "docs = vector_store.get_relevant_documents(\"Tell me about indian budget 2024\")\n",
    "doc_txt = docs[1].page_content\n",
    "print(retrieval_grader.invoke({\"question\": \"Tell me about indian budget 2024\", \"document\": doc_txt}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GENERATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Indian Budget for the fiscal year 2024-2025 was presented by Finance Minister Nirmala Sitharaman on July 23, 2024. The budget focuses on nine key priorities, including agriculture, employment, human resource development, manufacturing, urban development, energy security, and infrastructure. It aims to create opportunities for all citizens and contribute to India's development as envisioned in the \"Viksit Bharat\" initiative. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \" \".join(doc.page_content for doc in docs)\n",
    "\n",
    "question = \"Tell me about indian budget 2024\"\n",
    "\n",
    "rag_chain = prompt | llm | StrOutputParser()\n",
    "generation = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HALLUCINATION-GRADER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'args': {'binary_score': 'yes'}, 'type': 'Grade_Docs'}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Grade_Halucinations(BaseModel):\n",
    "    binary_score: str = Field(...,description = \"\"\"You are a grader assessing whether an LLM generation is grounded in /\n",
    "                              supported by a set of retrieved facts. \\n\n",
    "                              Give a binary score 'yes' or 'no'. \n",
    "                              'Yes' means that the answer is grounded in / supported by the set of facts.\"\"\")\n",
    "    \n",
    "\n",
    "hallucination_prompt = ChatPromptTemplate.from_messages([(\"system\", system),(\"human\", \"Set of facts: \\n\\n {documents} \\n\\n LLM generation: {generation}\"),])\n",
    "\n",
    "hallucination_grader = hallucination_prompt | llm_grader\n",
    "hallucination_grader.invoke({\"documents\": docs, \"generation\": generation})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER GRADER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnswerGrader(binary_score='yes')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AnswerGrader(BaseModel):\n",
    "    binary_score: str = Field(..., description=\"Does answer resolve query 'Yes' or 'No'.\")\n",
    "\n",
    "llm_ans_grader = llm.with_structured_output(AnswerGrader)\n",
    "system = \"\"\"You are a grader assessing whether an answer addresses / resolves a question.\n",
    "Give a binary score 'yes' or 'no'. 'Yes' means that the answer resolves the question.\"\"\"\n",
    "\n",
    "answer_prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", \"user question {question} \\n generation:{generation}\")])\n",
    "\n",
    "answer_grader = answer_prompt | llm_ans_grader\n",
    "answer_grader.invoke({\"question\": question, \"generation\": generation})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROMPT RE-WRITER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What are the key features and highlights of the Indian Budget for the fiscal year 2024? \\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system = \"\"\"You a question re-writer that converts an input question to a better version that is optimized \\n\n",
    "     for vectorstore retrieval. Look at the input and try to reason about the underlying semantic intent / meaning.\"\"\"\n",
    "\n",
    "\n",
    "rewrite_prompt = ChatPromptTemplate([(\"system\",system),(\"human\",\"Here is the initial question:\\n{question} formulate only one improved question\")])\n",
    "\n",
    "question_rewriter = rewrite_prompt | llm | StrOutputParser()\n",
    "question_rewriter.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WIKIPEDIA AGENT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page: Nirmala Sitharaman\\nSummary: Nirmala Sitharaman (born 18 August 1959) is an Indian economist, politician and a senior leader of the Bharatiya Janata Party (BJP) serving as the Minister of Finance'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_wrapper=ArxivAPIWrapper(top_k_results=1, doc_content_chars_max=200)\n",
    "arxiv=ArxivQueryRun(api_wrapper=arxiv_wrapper)\n",
    "\n",
    "api_wrapper=WikipediaAPIWrapper(top_k_results=1,doc_content_chars_max=200)\n",
    "wiki=WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "\n",
    "wiki.invoke(\"Who conducted Budget 2024 of india\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GRAPH**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphState(TypedDict):\n",
    "    question : str\n",
    "    generation : str\n",
    "    documents : List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state):\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    generation = rag_chain.invoke({\"context\":documents})\n",
    "    return {\"documents\": documents, \"question\": question, \"generation\": generation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_documents(state):\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    filtered_docs = []\n",
    "    for d in documents:\n",
    "        score = retrieval_grader.invoke(d.page_content)\n",
    "        if score == \"yes\":#IF THE DOCUMENT IS RELEVANT\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    return {\"documents\":filtered_docs,\"question\":question}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_query(state):\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    better_question = question_rewriter.invoke({\"question\":question})\n",
    "    return {\"documents\":documents,\"question\":better_question}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wiki_search(state):\n",
    "    question = state[\"question\"]\n",
    "    print(question)\n",
    "\n",
    "    docs = wiki.invoke(question)\n",
    "    wiki_results = docs\n",
    "    wiki_results = Document(page_content=wiki_results)\n",
    "\n",
    "    return {\"documents\": wiki_results, \"question\": question}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_question(state):\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    source = question_router.invoke({\"question\":question})\n",
    "    if source.datasource == \"wiki_search\":\n",
    "        return \"wiki_search\"\n",
    "    else:\n",
    "        return \"vector_store\"\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
