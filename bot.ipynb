{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader,DirectoryLoader\n",
    "from langchain_astradb import AstraDBVectorStore\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI,GoogleGenerativeAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel,Field\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.utilities import ArxivAPIWrapper,WikipediaAPIWrapper\n",
    "from langchain_community.tools import ArxivQueryRun,WikipediaQueryRun\n",
    "from langchain import hub\n",
    "from typing import List,Literal\n",
    "from typing_extensions import TypedDict\n",
    "from langchain.schema import Document\n",
    "from pprint import pprint\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "LANGCHAIN_API_KEY = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "LANGCHAIN_PROJECT=\"Langgraph_bot\"\n",
    "LANGCHAIN_TRACING_V2= True \n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a large language model, trained by Google. \n",
      "\n",
      "Here's what that means:\n",
      "\n",
      "* **I am a computer program:** I don't have feelings, experiences, or a physical body.\n",
      "* **I am trained on a massive amount of text data:** This allows me to communicate and generate human-like text in response to a wide range of prompts. \n",
      "* **I can help you with various tasks:** From answering questions to writing stories, translating languages, and summarizing text, I am here to assist you.\n",
      "\n",
      "How can I help you today? \n",
      "\n"
     ]
    }
   ],
   "source": [
    "llm = ChatGoogleGenerativeAI(model = \"gemini-1.5-pro\",api_key = GOOGLE_API_KEY,temperature = 0.2)\n",
    "print(llm.invoke(\"Who are you?\").content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATA-INGESTION & CONVERSION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf(data):\n",
    "    loader = DirectoryLoader(path = data,glob = \"*.pdf\",loader_cls = PyPDFLoader)\n",
    "    docs = loader.load()\n",
    "    return docs\n",
    "\n",
    "extracted_data = load_pdf(\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "\n",
    "\n",
    "    return text_chunks\n",
    "\n",
    "text_chunks = text_split(extracted_data)\n",
    "len(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "gemini_embeddings = GoogleGenerativeAIEmbeddings(model = \"models/embedding-001\")\n",
    "ASTRA_DB_API = os.getenv(\"ASTRA_API_KEY\")\n",
    "ASTRA_ENDPOINT = os.getenv(\"DB_ENDPOINT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest(status):\n",
    "    vector_store = AstraDBVectorStore(token = ASTRA_DB_API,\n",
    "                                      api_endpoint = ASTRA_ENDPOINT,\n",
    "                                      embedding = gemini_embeddings,\n",
    "                                      namespace = \"law\",\n",
    "                                      collection_name = \"langgraph_RAG\")\n",
    "    is_full = status\n",
    "    if is_full == None:#THIS MEANS THERE IS NO VECTORS CREATED IN DB\n",
    "        inserted_ids = vector_store.add_documents(text_chunks)\n",
    "    else:\n",
    "        return vector_store\n",
    "    \n",
    "    \n",
    "    return vector_store,inserted_ids\n",
    "\n",
    "vector_store = ingest(None)#IF YOU ARE RUNNING THIS FOR 2nd TIME CHANGE PARAMETER TO \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = AstraDBVectorStore(token = ASTRA_DB_API,\n",
    "                                      api_endpoint = ASTRA_ENDPOINT,\n",
    "                                      embedding = gemini_embeddings,\n",
    "                                      namespace = \"law\",\n",
    "                                      collection_name = \"langgraph_RAG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ROUTING IN THE GRAPGH**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Key 'title' is not supported in schema, ignoring\n",
      "Key 'title' is not supported in schema, ignoring\n",
      "Key 'title' is not supported in schema, ignoring\n",
      "Key 'title' is not supported in schema, ignoring\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'args': {'datasource': 'vectorstore'}, 'type': 'Route_Query'}]\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "\n",
    "class Route_Query(BaseModel):\n",
    "    datasource: Literal[\"vectorstore\", \"wiki_search\"] = Field(..., description=\"For a given user question decide whether to route it to vectorstore or wiki_search\")\n",
    "\n",
    "llm_router = llm.with_structured_output(Route_Query)\n",
    "\n",
    "system = \"\"\"You are an expert at routing a user question to a vectorstore or wiki_search.\n",
    "The vectorstore contains documents related to Indian law budget 2024.\n",
    "Use the vectorstore for questions on these topics. Otherwise, use wiki_search.\"\"\"\n",
    "\n",
    "route_prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", \"{question}\")])\n",
    "\n",
    "question_router = route_prompt | llm_router\n",
    "\n",
    "print(question_router.invoke({\"question\": \"Tell me about Shrimp Production & Export in budget 2024?\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DOCUMENT GRADER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Key 'title' is not supported in schema, ignoring\n",
      "Key 'title' is not supported in schema, ignoring\n",
      "Key 'title' is not supported in schema, ignoring\n",
      "Key 'title' is not supported in schema, ignoring\n",
      "c:\\a\\envs\\main\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'args': {'binary_score': 'yes'}, 'type': 'Grade_Docs'}]\n"
     ]
    }
   ],
   "source": [
    "class Grade_Docs(BaseModel):\n",
    "    binary_score : Literal[\"yes\",\"no\"] = Field(...,description = \"Documents are relevant to the question, 'yes' or 'no'\")\n",
    "\n",
    "system = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n\n",
    "    If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "    It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\"\n",
    "\n",
    "grade_prompt = ChatPromptTemplate.from_messages([(\"system\", system),(\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),])\n",
    "\n",
    "llm_grader = llm.with_structured_output(Grade_Docs)\n",
    "\n",
    "retrieval_grader = grade_prompt | llm_grader\n",
    "docs = vector_store.get_relevant_documents(\"Tell me about indian budget 2024\")\n",
    "doc_txt = docs[1].page_content\n",
    "print(retrieval_grader.invoke({\"question\": \"Tell me about indian budget 2024\", \"document\": doc_txt}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
